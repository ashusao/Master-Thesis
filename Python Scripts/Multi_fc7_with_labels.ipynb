{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ashu/Desktop/Thesis Work/Classifier/caffe/models/script\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "#matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "caffe_root = '/home/ashu/Desktop/Thesis Work/Classifier/caffe/'\n",
    "print os.getcwd()\n",
    "sys.path.insert(0, caffe_root + 'python')\n",
    "import caffe\n",
    "\n",
    "import argparse\n",
    "\n",
    "from caffe.proto import caffe_pb2\n",
    "import google.protobuf as pb2\n",
    "import google.protobuf.text_format\n",
    "\n",
    "import lmdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load class labels and binary state labels , save them in two seperate dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9846 9846\n",
      "9846 9846 9846\n"
     ]
    }
   ],
   "source": [
    "cls_lbl_file = caffe_root + 'data/5_class_dataset/labels/val.txt'\n",
    "# read the labels file\n",
    "with open(cls_lbl_file, 'r') as f:\n",
    "    cls_data=f.readlines()\n",
    "    \n",
    "cls_data = [x.strip() for x in cls_data]\n",
    "\n",
    "# append image name and its label in a dictionary\n",
    "cls_lbl = {}\n",
    "for val in cls_data:\n",
    "    img, lbl = val.split(' ')\n",
    "    cls_lbl[img] = lbl\n",
    "    \n",
    "print len(cls_data), len(cls_lbl)\n",
    "\n",
    "# load all states indexed acc to img id in a dictionary\n",
    "state_lbl = {}\n",
    "st_lbl_laptop = caffe_root + 'data/5_class_dataset/labels/val_laptop_state.txt'\n",
    "st_lbl_scissor = caffe_root + 'data/5_class_dataset/labels/val_scissor_state.txt'\n",
    "st_lbl_suitcase = caffe_root + 'data/5_class_dataset/labels/val_suitcase_state.txt'\n",
    "st_lbl_toilet = caffe_root + 'data/5_class_dataset/labels/val_toilet_state.txt'\n",
    "st_lbl_umbrella = caffe_root + 'data/5_class_dataset/labels/val_umbrella_state.txt'\n",
    "\n",
    "with open(st_lbl_laptop, 'r') as f:\n",
    "    st_data_laptop=f.readlines()    \n",
    "st_data_laptop = [x.strip() for x in st_data_laptop]\n",
    "\n",
    "with open(st_lbl_scissor, 'r') as f:\n",
    "    st_data_scissor=f.readlines()    \n",
    "st_data_scissor = [x.strip() for x in st_data_scissor]\n",
    "\n",
    "with open(st_lbl_suitcase, 'r') as f:\n",
    "    st_data_suitcase=f.readlines()    \n",
    "st_data_suitcase = [x.strip() for x in st_data_suitcase]\n",
    "\n",
    "with open(st_lbl_toilet, 'r') as f:\n",
    "    st_data_toilet=f.readlines()    \n",
    "st_data_toilet = [x.strip() for x in st_data_toilet]\n",
    "\n",
    "with open(st_lbl_umbrella, 'r') as f:\n",
    "    st_data_umbrella=f.readlines()    \n",
    "st_data_umbrella = [x.strip() for x in st_data_umbrella]\n",
    "\n",
    "# concatenating all list\n",
    "st_data = st_data_laptop + st_data_scissor + st_data_suitcase + st_data_toilet + st_data_umbrella\n",
    "\n",
    "# appending the state information in one dictionary\n",
    "for val in st_data:\n",
    "    img, lbl = val.split(' ')\n",
    "    state_lbl[img] = lbl\n",
    "    \n",
    "    \n",
    "print len(cls_data), len(state_lbl), len(st_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load model and prototxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "caffe.set_mode_gpu()\n",
    "\n",
    "c_type = 'gt'\n",
    "max_iter = '50000'\n",
    "best_iter = '47000'\n",
    "# Modify the paths given below\n",
    "deploy_prototxt_file_path = caffe_root + 'models/' + c_type + '_classifier/all/test.prototxt'\n",
    "# load each caffe model\n",
    "caffe_model_file_path = caffe_root + 'models/gt_classifier/all/trained_model/' + \\\n",
    "                        'gt_all_' +  max_iter + \\\n",
    "                        '_iter_' + best_iter + '.caffemodel'\n",
    "net = caffe.Net(deploy_prototxt_file_path, caffe_model_file_path, caffe.TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- set the transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean-subtracted values: [('B', 104.0069879317889), ('G', 116.66876761696767), ('R', 122.6789143406786)]\n"
     ]
    }
   ],
   "source": [
    "# load the mean ImageNet image (as distributed with Caffe) for subtraction\n",
    "mu = np.load(caffe_root + 'python/caffe/imagenet/ilsvrc_2012_mean.npy')\n",
    "mu = mu.mean(1).mean(1)  # average over pixels to obtain the mean (BGR) pixel values\n",
    "print 'mean-subtracted values:', zip('BGR', mu)\n",
    "\n",
    "# create transformer for the input called 'data'\n",
    "transformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})\n",
    "\n",
    "transformer.set_transpose('data', (2,0,1))  # move image channels to outermost dimension\n",
    "transformer.set_mean('data', mu)            # subtract the dataset-mean value in each channel\n",
    "transformer.set_raw_scale('data', 255)      # rescale from [0, 1] to [0, 255]\n",
    "transformer.set_channel_swap('data', (2,1,0))  # swap channels from RGB to BGR\n",
    "\n",
    "net.blobs['data'].reshape(1,        # batch size\n",
    "                          3,         # 3-channel (BGR) images\n",
    "                          224, 224)  # image size is 227x227"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- iterate through images and save fc7 and its gt label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global_fc7 = []\n",
    "global_fc7_new = []\n",
    "class_labels = []\n",
    "#fc7_vectors = [[] for _ in range(5)]\n",
    "#fc7_new_vectors = [[] for _ in range(5)]\n",
    "#state_labels = [[] for _ in range(5)]\n",
    "\n",
    "# extract weight\n",
    "wt = net.params['cls_score'][0].data[...].clip(min=0)\n",
    "img_dir = caffe_root + 'data/5_class_dataset/images/val/'\n",
    "\n",
    "for k,v in cls_lbl.iteritems():\n",
    "    img, lbl = val.split(' ')\n",
    "    \n",
    "    # load image, transform and feed forward\n",
    "    image = caffe.io.load_image(img_dir + k)\n",
    "    transformed_image = transformer.preprocess('data', image)\n",
    "    net.blobs['data'].data[...] = transformed_image\n",
    "    output = net.forward()\n",
    "    label = int(v)\n",
    "    \n",
    "    # append generated fc7 to global fc7 vectors\n",
    "    global_fc7.append(net.blobs['fc7'].data.copy())\n",
    "    class_labels.append(int(v))\n",
    "    \n",
    "    if label == 0: #gt laptop\n",
    "        #fc7_vectors[0].append(net.blobs['fc7'].data.copy())\n",
    "        #fc7_new_vectors[0].append(net.blobs['fc7'].data.copy() * wt[0])\n",
    "        #state_labels[0].append(state_lbl[k])\n",
    "        global_fc7_new.append(net.blobs['fc7'].data.copy() * wt[0])\n",
    "        continue\n",
    "        \n",
    "    if label == 1: #gt scissor\n",
    "        #fc7_vectors[1].append(net.blobs['fc7'].data.copy())\n",
    "        #fc7_new_vectors[1].append(net.blobs['fc7'].data.copy() * wt[1])\n",
    "        #state_labels[1].append(state_lbl[k])\n",
    "        global_fc7_new.append(net.blobs['fc7'].data.copy() * wt[1])\n",
    "        continue\n",
    "        \n",
    "    if label == 2: #gt suitcase\n",
    "        #fc7_vectors[2].append(net.blobs['fc7'].data.copy())\n",
    "        #fc7_new_vectors[2].append(net.blobs['fc7'].data.copy() * wt[2])\n",
    "        #state_labels[2].append(state_lbl[k])\n",
    "        global_fc7_new.append(net.blobs['fc7'].data.copy() * wt[2])\n",
    "        continue\n",
    "        \n",
    "    if label == 3: #gt toilet\n",
    "        #fc7_vectors[3].append(net.blobs['fc7'].data.copy())\n",
    "        #fc7_new_vectors[3].append(net.blobs['fc7'].data.copy() * wt[3])\n",
    "        #state_labels[3].append(state_lbl[k])\n",
    "        global_fc7_new.append(net.blobs['fc7'].data.copy() * wt[3])\n",
    "        continue\n",
    "        \n",
    "    if label == 4: #gt umbrella\n",
    "        #fc7_vectors[4].append(net.blobs['fc7'].data.copy())\n",
    "        #fc7_new_vectors[4].append(net.blobs['fc7'].data.copy() * wt[4])\n",
    "        #state_labels[4].append(state_lbl[k])\n",
    "        global_fc7_new.append(net.blobs['fc7'].data.copy() * wt[4])\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  0 :\n",
      "fc7 : \n",
      "[array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  4.38832045]], dtype=float32), array([[ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32), array([[ 2.25579   ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.42316282]], dtype=float32)]\n",
      "fc7 new : \n",
      "[array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.00488022]], dtype=float32), array([[ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32), array([[ 0.       ,  0.       ,  0.       , ...,  0.       ,  0.       ,\n",
      "         0.0004706]], dtype=float32)]\n",
      "State Label : \n",
      "['0', '0', '0']\n",
      "For  1 :\n",
      "fc7 : \n",
      "[array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.96149957]], dtype=float32), array([[ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32), array([[ 0.11939523,  0.        ,  2.18348169, ...,  0.        ,\n",
      "         0.        ,  0.30500969]], dtype=float32)]\n",
      "fc7 new : \n",
      "[array([[ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32), array([[ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32), array([[ 0.00119187,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ]], dtype=float32)]\n",
      "State Label : \n",
      "['1', '1', '1']\n",
      "For  2 :\n",
      "fc7 : \n",
      "[array([[ 0.        ,  0.        ,  0.72384149, ...,  0.        ,\n",
      "         0.        ,  0.21219775]], dtype=float32), array([[ 0.        ,  0.        ,  1.50960934, ...,  0.53013849,\n",
      "         0.        ,  0.29139492]], dtype=float32), array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.62011003]], dtype=float32)]\n",
      "fc7 new : \n",
      "[array([[ 0.        ,  0.        ,  0.01134285, ...,  0.        ,\n",
      "         0.        ,  0.        ]], dtype=float32), array([[ 0.        ,  0.        ,  0.0236561 , ...,  0.00813207,\n",
      "         0.        ,  0.        ]], dtype=float32), array([[ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32)]\n",
      "State Label : \n",
      "['1', '1', '1']\n",
      "For  3 :\n",
      "fc7 : \n",
      "[array([[ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32), array([[ 0.32382175,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.53470051]], dtype=float32), array([[ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32)]\n",
      "fc7 new : \n",
      "[array([[ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32), array([[ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32), array([[ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32)]\n",
      "State Label : \n",
      "['1', '0', '1']\n",
      "For  4 :\n",
      "fc7 : \n",
      "[array([[ 4.13889694,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  3.46714425]], dtype=float32), array([[ 0.9349013 ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  4.08776999]], dtype=float32), array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  4.14218521]], dtype=float32)]\n",
      "fc7 new : \n",
      "[array([[ 0.05170796,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.1014332 ]], dtype=float32), array([[ 0.01167988,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.11958994]], dtype=float32), array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.12118188]], dtype=float32)]\n",
      "State Label : \n",
      "['0', '0', '0']\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print 'For ', i , ':'\n",
    "    print 'fc7 : \\n', fc7_vectors[i][:3]\n",
    "    print 'fc7 new : \\n', fc7_new_vectors[i][:3]\n",
    "    print 'State Label : \\n', state_labels[i][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1802 1802 1802\n",
      "439 439 439\n",
      "2216 2216 2216\n",
      "1454 1454 1454\n",
      "3935 3935 3935\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print len(fc7_vectors[i]), len(fc7_new_vectors[i]), len(state_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for global fc7 only\n",
    "import pickle\n",
    "fc7_dir = caffe_root + 'models/' + c_type + '_classifier/all/fc7/'\n",
    "if not os.path.exists(fc7_dir):\n",
    "    os.makedirs(fc7_dir)\n",
    "    \n",
    "global_fc7_file = fc7_dir + c_type + '_fc7_global.pkl'\n",
    "global_fc7_new_file = fc7_dir + c_type + '_fc7_new_global.pkl'\n",
    "cls_lbl_file = fc7_dir + c_type + '_label_global.pkl'\n",
    "\n",
    "# dump fc7 features\n",
    "fileObject = open(global_fc7_file,'wb')\n",
    "pickle.dump(global_fc7,fileObject)\n",
    "fileObject.close()\n",
    "    \n",
    "# dump fc7 new features\n",
    "fileObject = open(global_fc7_new_file,'wb')\n",
    "pickle.dump(global_fc7_new,fileObject)\n",
    "fileObject.close()\n",
    "\n",
    "# dump state labels\n",
    "fileObject = open(cls_lbl_file,'wb')\n",
    "pickle.dump(class_labels,fileObject)\n",
    "fileObject.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ashu/Desktop/Thesis Work/Classifier/caffe/models/gt_classifier/all/fc7/ /home/ashu/Desktop/Thesis Work/Classifier/caffe/models/gt_classifier/all/fc7/gt_fc7_laptop.pkl /home/ashu/Desktop/Thesis Work/Classifier/caffe/models/gt_classifier/all/fc7/gt_label_laptop.pkl\n",
      "done.\n",
      "/home/ashu/Desktop/Thesis Work/Classifier/caffe/models/gt_classifier/all/fc7/ /home/ashu/Desktop/Thesis Work/Classifier/caffe/models/gt_classifier/all/fc7/gt_fc7_scissor.pkl /home/ashu/Desktop/Thesis Work/Classifier/caffe/models/gt_classifier/all/fc7/gt_label_scissor.pkl\n",
      "done.\n",
      "/home/ashu/Desktop/Thesis Work/Classifier/caffe/models/gt_classifier/all/fc7/ /home/ashu/Desktop/Thesis Work/Classifier/caffe/models/gt_classifier/all/fc7/gt_fc7_suitcase.pkl /home/ashu/Desktop/Thesis Work/Classifier/caffe/models/gt_classifier/all/fc7/gt_label_suitcase.pkl\n",
      "done.\n",
      "/home/ashu/Desktop/Thesis Work/Classifier/caffe/models/gt_classifier/all/fc7/ /home/ashu/Desktop/Thesis Work/Classifier/caffe/models/gt_classifier/all/fc7/gt_fc7_toilet.pkl /home/ashu/Desktop/Thesis Work/Classifier/caffe/models/gt_classifier/all/fc7/gt_label_toilet.pkl\n",
      "done.\n",
      "/home/ashu/Desktop/Thesis Work/Classifier/caffe/models/gt_classifier/all/fc7/ /home/ashu/Desktop/Thesis Work/Classifier/caffe/models/gt_classifier/all/fc7/gt_fc7_umbrella.pkl /home/ashu/Desktop/Thesis Work/Classifier/caffe/models/gt_classifier/all/fc7/gt_label_umbrella.pkl\n",
      "done.\n",
      "completed\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "fc7_dir = caffe_root + 'models/' + c_type + '_classifier/all/fc7/'\n",
    "if not os.path.exists(fc7_dir):\n",
    "    os.makedirs(fc7_dir)\n",
    "\n",
    "objs = ['laptop', 'scissor', 'suitcase', 'toilet', 'umbrella']    \n",
    "\n",
    "for i,o in enumerate(objs):   \n",
    "    fc7_file = fc7_dir + c_type + '_fc7_' + o + '.pkl'\n",
    "    fc7_new_file = fc7_dir + c_type + '_fc7_new_' + o + '.pkl'\n",
    "    lbl_file = fc7_dir + c_type + '_label_' + o + '.pkl'\n",
    "    \n",
    "    # dump fc7 features\n",
    "    fileObject = open(fc7_file,'wb')\n",
    "    pickle.dump(fc7_vectors[i],fileObject)\n",
    "    fileObject.close()\n",
    "    \n",
    "    # dump fc7 new features\n",
    "    fileObject = open(fc7_new_file,'wb')\n",
    "    pickle.dump(fc7_new_vectors[i],fileObject)\n",
    "    fileObject.close()\n",
    "\n",
    "    # dump state labels\n",
    "    fileObject = open(lbl_file,'wb')\n",
    "    pickle.dump(state_labels[i],fileObject)\n",
    "    fileObject.close()\n",
    "    \n",
    "    print fc7_dir, fc7_file, lbl_file\n",
    "    print 'done.'\n",
    "\n",
    "print 'completed'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
