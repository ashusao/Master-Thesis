{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ashu/Desktop/Thesis Work/Classifier/caffe/models/script\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "#matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "caffe_root = '/home/ashu/Desktop/Thesis Work/Classifier/caffe/'\n",
    "print os.getcwd()\n",
    "sys.path.insert(0, caffe_root + 'python')\n",
    "import caffe\n",
    "\n",
    "from PIL import Image\n",
    "import argparse\n",
    "\n",
    "from caffe.proto import caffe_pb2\n",
    "import google.protobuf as pb2\n",
    "import google.protobuf.text_format\n",
    "\n",
    "import lmdb\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load Detections of Val Set for the category specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18966\n",
      "['COCO_val2014_000000568337 0.269 383.0 183.7 470.4 222.1'\n",
      " 'COCO_val2014_000000568337 0.162 38.2 84.8 383.2 428.0'\n",
      " 'COCO_val2014_000000193720 0.551 327.6 90.4 543.0 422.4'\n",
      " 'COCO_val2014_000000039663 0.299 331.4 60.1 347.8 149.0'\n",
      " 'COCO_val2014_000000039663 0.268 374.5 71.7 390.2 144.3'\n",
      " 'COCO_val2014_000000039663 0.099 321.9 57.8 337.6 145.6'\n",
      " 'COCO_val2014_000000504224 0.444 391.6 395.8 634.4 480.0']\n"
     ]
    }
   ],
   "source": [
    "object_name = 'umbrella'\n",
    "det_file = caffe_root + 'data/det_val/det_val_' + object_name + '.txt'\n",
    "\n",
    "with open(det_file, 'r') as f:\n",
    "    lines = np.array(f.readlines()) \n",
    "    \n",
    "remove_new_line = np.vectorize(lambda x: x.strip())\n",
    "lines = remove_new_line(lines)\n",
    "\n",
    "print len(lines)\n",
    "print lines[:7]\n",
    "\n",
    "images_root = '/home/ashu/Study Material/Uni Bonn/4th Semester/Thesis/DataSet/coco-master/JPEGImages/'\n",
    "#temporary images folder to save cropped images\n",
    "tmp_img = caffe_root + 'models/gt_classifier/tmp_images/' + object_name + '/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load Images, crop the detections and save it into a temporary folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "if not os.path.exists(tmp_img):\n",
    "    os.makedirs(tmp_img)\n",
    "\n",
    "for i, det in enumerate(lines):  # for first 10 only\n",
    "    val = det.split(' ')\n",
    "    img = Image.open(images_root + val[0] + '.jpg')\n",
    "    #print val[0]\n",
    "    new_img = img.crop((float(val[2]), float(val[3]), float(val[4]), float(val[5]))) #.resize((224,224))\n",
    "    new_img_name = val[0] + '_' + str(i) + '.jpg'\n",
    "    new_img.save(tmp_img + new_img_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Open two files for open and close State\n",
    "- Loop Through list, load image, crop ,resize and feed into classifier\n",
    "- predict state labels, fc7 feature and confidence\n",
    "- According to labels add Img Id, confidence, x1, y1, x2, y2 to open or close state file\n",
    "- add fc7 feature and label to features file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean-subtracted values: [('B', 104.0069879317889), ('G', 116.66876761696767), ('R', 122.6789143406786)]\n",
      "Open: \n",
      "  ['COCO_val2014_000000568337 0.267875399828 383.0 183.7 470.4 222.1\\n', 'COCO_val2014_000000568337 0.161996214867 38.2 84.8 383.2 428.0\\n']\n",
      "Close: \n",
      "  ['COCO_val2014_000000193720 0.301764433086 327.6 90.4 543.0 422.4\\n', 'COCO_val2014_000000039663 0.298997968316 331.4 60.1 347.8 149.0\\n']\n"
     ]
    }
   ],
   "source": [
    "# list for storing detections of each state\n",
    "open_state = []\n",
    "close_state = []\n",
    "fc7_vectors = []\n",
    "label_list = []\n",
    "\n",
    "# tmp saved image path\n",
    "tmp_img = caffe_root + 'models/gt_classifier/tmp_images/' + object_name + '/'\n",
    "\n",
    "caffe.set_mode_gpu()\n",
    "\n",
    "max_iter = '40000'\n",
    "best_iter = '30000'\n",
    "# Modify the paths given below\n",
    "deploy_prototxt_file_path = caffe_root + 'models/gt_classifier/gen_' + object_name +  \\\n",
    "                            '/test.prototxt' # Network definition file\n",
    "# load each caffe model\n",
    "caffe_model_file_path = caffe_root + 'models/gt_classifier/gen_' + object_name + \\\n",
    "                        '/gen_' + object_name + '_' + max_iter + \\\n",
    "                        '_iter_' + best_iter + '.caffemodel' \n",
    "        \n",
    "net = caffe.Net(deploy_prototxt_file_path,      # defines the structure of the model\n",
    "                caffe_model_file_path,  # contains the trained weights\n",
    "                caffe.TEST)     # use test mode (e.g., don't perform dropout)\n",
    "\n",
    "# load the mean ImageNet image (as distributed with Caffe) for subtraction\n",
    "mu = np.load(caffe_root + 'python/caffe/imagenet/ilsvrc_2012_mean.npy')\n",
    "mu = mu.mean(1).mean(1)  # average over pixels to obtain the mean (BGR) pixel values\n",
    "print 'mean-subtracted values:', zip('BGR', mu)\n",
    "\n",
    "# create transformer for the input called 'data'\n",
    "transformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})\n",
    "\n",
    "transformer.set_transpose('data', (2,0,1))  # move image channels to outermost dimension\n",
    "transformer.set_mean('data', mu)            # subtract the dataset-mean value in each channel\n",
    "transformer.set_raw_scale('data', 255)      # rescale from [0, 1] to [0, 255]\n",
    "transformer.set_channel_swap('data', (2,1,0))  # swap channels from RGB to BGR\n",
    "\n",
    "net.blobs['data'].reshape(1,        # batch size\n",
    "                          3,         # 3-channel (BGR) images\n",
    "                          224, 224)  # image size is 227x227\n",
    "\n",
    "for i, det in enumerate(lines):  # for first 10 only\n",
    "    val = det.split(' ')\n",
    "    new_img_name = val[0] + '_' + str(i) + '.jpg'\n",
    "    # copy the image data into the memory allocated for the net\n",
    "    image = caffe.io.load_image(tmp_img + new_img_name)\n",
    "    transformed_image = transformer.preprocess('data', image)\n",
    "    net.blobs['data'].data[...] = transformed_image\n",
    "\n",
    "    ### perform classification\n",
    "    output = net.forward()\n",
    "\n",
    "    output_prob = output['prob']  # the output probability vector for the first image in the batch\n",
    "\n",
    "    #print 'predicted score: ', output_prob\n",
    "    state_label = output_prob[0].argmax()\n",
    "    #print i, ': predicted class is:', state_label\n",
    "    \n",
    "    cnf = output_prob[0][output_prob.argmax()]\n",
    "    \n",
    "    # confidence = cnf by detections * cnf of classifier\n",
    "    new_cnf = cnf * float(val[1])\n",
    "    new_det = val[0] + ' ' + str(new_cnf) + ' ' + val[2] + ' ' + val[3] + ' ' + val[4] + ' ' + val[5]\n",
    "    \n",
    "    # append fc7 vectir and labels to list\n",
    "    fc7_vectors.append(net.blobs['fc7'].data.copy())\n",
    "    label_list.append(state_label)\n",
    "    \n",
    "    if state_label == 0:\n",
    "        open_state.append(new_det + '\\n')\n",
    "    else:\n",
    "        close_state.append(new_det + '\\n')\n",
    "        \n",
    "print 'Open: \\n ', open_state[:2]\n",
    "print 'Close: \\n ', close_state[:2]\n",
    "#print 'fc7: \\n', fc7_vectors[-4:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4812\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# chek fc7 output\n",
    "fc7 = np.array(fc7_vectors)\n",
    "print fc7.shape[0]\n",
    "for i in range(fc7.shape[0]):\n",
    "    if not np.allclose(fc7[0][0], fc7[i][0]):\n",
    "        print i\n",
    "        break\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Save Detections in seperate folder for open and close state classified acc to classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ashu/Desktop/Thesis Work/Classifier/caffe/models/gt_classifier/gen_umbrella/detections/gen_val_openUmbrella.txt /home/ashu/Desktop/Thesis Work/Classifier/caffe/models/gt_classifier/gen_umbrella/detections/gen_val_closedUmbrella.txt\n"
     ]
    }
   ],
   "source": [
    "det_dir = caffe_root + 'models/gt_classifier/gen_' + object_name + '/detections/'\n",
    "if not os.path.exists(det_dir):\n",
    "    os.makedirs(det_dir)\n",
    "    \n",
    "open_fileName = det_dir + 'gen_val_open'  + object_name.title() + '.txt'\n",
    "close_fileName = det_dir + 'gen_val_closed'  + object_name.title() + '.txt'\n",
    "\n",
    "print open_fileName, close_fileName\n",
    "\n",
    "#write into file\n",
    "with open(open_fileName, 'w+') as f:\n",
    "    for val in open_state:\n",
    "        f.write(val)\n",
    "        \n",
    "#write into file\n",
    "with open(close_fileName, 'w+') as f:\n",
    "    for val in close_state:\n",
    "        f.write(val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Save fc7 feature and its label using pickle dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4265 4265\n",
      "[array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.17291714]], dtype=float32), array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.70667338]], dtype=float32), array([[ 0.        ,  0.        ,  0.        , ...,  0.08704553,\n",
      "         0.06781743,  1.52062988]], dtype=float32)]\n",
      "[1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "det_dir = caffe_root + 'models/gt_classifier/' + object_name + '/detections/'\n",
    "\n",
    "fc7_file = det_dir+ 'gt_val_fc7_' + object_name + '.pkl'\n",
    "lbl_file = det_dir+ 'gt_val_fc7_label_' + object_name + '.pkl'\n",
    "\n",
    "'''\n",
    "def format(value):\n",
    "    return \"%.3f\" % value\n",
    "\n",
    "formatted = [[format(v) for v in r] for r in fc7_vectors]\n",
    "'''\n",
    "# dump fc7 features\n",
    "fileObject = open(fc7_file,'wb')\n",
    "pickle.dump(fc7_vectors,fileObject)\n",
    "fileObject.close()\n",
    "\n",
    "# dump state labels\n",
    "fileObject = open(lbl_file,'wb')\n",
    "pickle.dump(label_list,fileObject)\n",
    "fileObject.close()\n",
    "\n",
    "print len(fc7_vectors), len(label_list)\n",
    "print fc7_vectors[:3]\n",
    "print label_list[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- load pickle and check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8942 8942\n",
      "[array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  2.33277202]], dtype=float32), array([[ 0.        ,  0.32808748,  0.        , ...,  0.        ,\n",
      "         1.74012995,  2.361202  ]], dtype=float32), array([[ 0.       ,  0.       ,  0.       , ...,  0.       ,  0.       ,\n",
      "         0.5555228]], dtype=float32)]\n",
      "[0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "fileObject = open(fc7_file,'r')  \n",
    "# load the object from the file into var b\n",
    "loaded_fc7 = pickle.load(fileObject)  \n",
    "fileObject.close()\n",
    "\n",
    "fileObject = open(lbl_file,'r')  \n",
    "# load the object from the file into var b\n",
    "loaded_lbl= pickle.load(fileObject)  \n",
    "fileObject.close()\n",
    "\n",
    "print len(loaded_fc7), len(loaded_lbl)\n",
    "print loaded_fc7[:3]\n",
    "print loaded_lbl[:3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
